% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ToM.R
\name{gradient_update}
\alias{gradient_update}
\title{gradient_update}
\usage{
gradient_update(opponent_prev_hidden_states, params, mean, param_mean,
  reverse_choices, opponent_level, opponent_player, p_matrix.)
}
\arguments{
\item{opponent_prev_hidden_states}{opponents previous hidden states}

\item{mean}{the mean of k-ToM's choice probability estimate of its opponent}

\item{param_mean}{the means of k-ToM's parameter estimates}

\item{reverse_choices}{a vector of k-ToM's 1 opponent's choice and 2 own choice. Inserted as choices when simulating the opponent}

\item{opponent_level}{the level of the opponent for which the gradient is calculated}

\item{opponent_player}{the reverse player role of k-ToM's own. Inserted as player role when simulaitng the opponent}

\item{p_matrix}{a given 2-by-2 payoff matrix}
}
\value{
The gradient between each parameter estimate and the choice probability estimate
}
\description{
k-ToM calculates the gradient between parameter estimates and choice probability estimates
}
\references{
Devaine et al. (2014a, 2014b, 2017)
}
\author{
K. Enevoldsen & P. Waade
}
